{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Humboldt-WI/adams/blob/master/exercises/tut7_RNN_NLP1_teacher.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 7: Processing words as sequences\n",
    "In this tutorial, we will try to predict the next word in a sentence. This is challenging, as we will see because we choose a word out of a vocabulary, which is commonly large. Hence, the purpose of this tutorial is not to get an accurate model, but rather to show you how this task can be performed. More accurate models require larger samples and computational resources. \n",
    "\n",
    "We cover the following\n",
    "1. Prepare the text data to represent the sequence $[w_1,w_2,w_3,w_4,w_5,w_6]$ into something like $y=w_6$ and $x=[w_1,w_2,w_3,w_4,w_5]$. Because you are now familiar with IMBD dataset, we will use it to create our sequence data.\n",
    "2. Train a feedforward network. \n",
    "3. Train a NN with `SimpleRNN` layer. \n",
    "4. Train a NN with `LSTM` layer.\n",
    "5. Train a NN with `Embedding` and `LSTM` layers.\n",
    "\n",
    "For further examples, please visit the demos in [demos/rnn](https://github.com/Humboldt-WI/adams/tree/master/demos/rnn)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocess IMDB data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import string\n",
    "import re\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "Load the IMDB, and use the first 100 reviews as training and the next 20 as validation. We won't be using the sentiment, only the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\",\n",
       "       'A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data (be sure to provide the correct file path)\n",
    "total_imbd = pd.read_csv(\"IMDB-50K-Movie-Review.zip\", sep=\",\", encoding=\"ISO-8859-1\")\n",
    "text_data = total_imbd['review'][:120].to_numpy()\n",
    "text_data_train = text_data[:100]\n",
    "text_data_val = text_data[100:]\n",
    "text_data_train[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "Create `our_standardization` function to convert to lowercase, remove HTML tags, punctation and double spaces (check [tut5_embeddings](https://github.com/Humboldt-WI/adams/blob/master/exercises/tut5_embeddings_teacher.ipynb)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_standardization(text_data):\n",
    "  lowercase = tf.strings.lower(text_data) # convert to lowercase\n",
    "  remove_html = tf.strings.regex_replace(lowercase, '<br />', ' ') # remove HTML tags\n",
    "  pattern_remove_punctuation = '[%s]' % re.escape(string.punctuation) # pattern to remove punctuation\n",
    "  remove_punct = tf.strings.regex_replace(remove_html, pattern_remove_punctuation, '') # apply pattern\n",
    "  remove_double_spaces = tf.strings.regex_replace(remove_punct, '\\s+', ' ') # remove double space\n",
    "  return remove_double_spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "Create `TextVectorization` with `output_mode` integer and without defining the `output_sequence_length`. Use only 100 words as vocabulary (nothing good can be done with 100 words, but the purpose is to illustrate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the size of the vocabulary and the max number of words in a sequence\n",
    "vocab_size = 100\n",
    "# Create a vectorization layer\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize = our_standardization,\n",
    "    max_tokens = vocab_size )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "Adapt the vectorization layer to the text_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', 'the', 'a', 'and', 'of', 'to', 'is', 'in', 'it']\n"
     ]
    }
   ],
   "source": [
    "# To create the vocabulary, we need to call adapt. The input is only the text\n",
    "vectorize_layer.adapt(text_data)\n",
    "# Check the first 10 words of the vocabulary. It is sorted by frequency \n",
    "vocab = vectorize_layer.get_vocabulary()\n",
    "print(vocab[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "Create `transform_text` function to transform the text data into a time serie. The targets are related with their previous 5 words (similar to what we saw in [tut6_LSTM](https://github.com/Humboldt-WI/adams/blob/master/exercises/tut6_LSTM_teacher.ipynb). You can use built-in `timeseries_dataset_from_array` from Keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text(data, sequence_length):\n",
    "    delay = sequence_length # the target word is the word after the sequence\n",
    "    batch_size = 1\n",
    "    flag = True\n",
    "    # Generate data\n",
    "    for rev in data:\n",
    "        vec_rev = vectorize_layer(rev) \n",
    "        # Create time series dataset for each review\n",
    "        aux_dataset = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "            data = vec_rev,\n",
    "            targets = vec_rev[delay:],\n",
    "            sequence_length=sequence_length,\n",
    "            shuffle=False,\n",
    "            batch_size=batch_size)\n",
    "        \n",
    "        # Concatenate the time series\n",
    "        for input, target in aux_dataset:\n",
    "            if flag:\n",
    "                X = input\n",
    "                y = target\n",
    "                flag = False\n",
    "            else:     \n",
    "                X = tf.concat([X , input], 0)\n",
    "                y = tf.concat([y, target], 0)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "Create the training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 5 # we use the last 5 words\n",
    "X_train, y_train = transform_text(text_data_train, sequence_length)\n",
    "X_val, y_val = transform_text(text_data_val, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: tf.Tensor([31  5  2 82  1], shape=(5,), dtype=int64)  target: tf.Tensor(43, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(\"features:\", X_train[0],\" target:\", y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(304,), dtype=int64, numpy=\n",
       "array([31,  5,  2, 82,  1, 43,  1, 12,  1,  1, 35,  1,  1,  1,  1, 32,  1,\n",
       "       40, 28,  1, 15, 10,  7,  1, 44,  1, 14, 60,  2, 86,  1, 12,  1, 60,\n",
       "       42,  1, 13, 23,  1,  4,  1,  1,  5,  1, 50,  1,  8,  1, 36,  2,  1,\n",
       "        1,  1, 60, 10,  7, 22,  3,  1, 17,  2,  1,  1, 38,  1, 10,  1,  1,\n",
       "       49,  1, 14,  1,  6,  1,  1, 38,  1, 23,  7,  1,  8,  2,  1,  1,  5,\n",
       "        2,  1,  9,  7,  1,  1, 15, 12,  7,  2,  1,  1,  6,  2,  1,  1,  1,\n",
       "        1,  1,  9,  1,  1, 20,  1,  1, 34,  1,  1,  5,  2,  1, 88, 30,  2,\n",
       "        1, 29,  1,  1,  4,  1,  1, 39,  1,  7, 22,  1, 20,  2,  1,  1,  1,\n",
       "        7,  1,  6,  1,  1,  1,  1,  1,  1,  1,  4,  1,  1,  1,  1,  1,  1,\n",
       "        4,  1,  1, 28, 83,  1,  1, 11, 62,  1,  2,  1,  1,  5,  2,  1,  7,\n",
       "        1,  6,  2,  1, 12,  9,  1, 88, 82,  1,  1,  1,  1,  1,  1,  1, 17,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  2, 86,  1, 11,  1,  1,  1, 60,\n",
       "       15, 39,  1,  9, 13,  1, 11,  1,  1, 11, 13,  1, 17,  9, 18, 15, 11,\n",
       "        1, 47, 11,  1,  3,  1, 17,  1,  4,  1,  1,  6,  2,  1,  1,  5,  1,\n",
       "        1, 22, 35,  1, 18,  1,  1,  1,  1, 32,  1, 45, 17,  3,  1,  1,  1,\n",
       "        1, 20,  1,  4, 84,  1, 14,  9, 90,  1,  1,  1,  1,  1,  1, 75,  1,\n",
       "        1,  1,  6, 65,  1,  5,  1,  1, 38,  1,  1,  1,  1, 24,  1,  1,  1,\n",
       "       14, 44,  7,  1,  1, 46, 24,  1, 84,  8,  1, 14,  1,  1,  1],\n",
       "      dtype=int64)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer(text_data_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 691), dtype=int64, numpy=\n",
       "array([[31,  5,  2, ...,  0,  0,  0],\n",
       "       [ 3,  1,  1, ...,  0,  0,  0],\n",
       "       [11,  1, 10, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [90, 11, 37, ...,  0,  0,  0],\n",
       "       [10,  7,  2, ...,  0,  0,  0],\n",
       "       [11, 29, 72, ...,  0,  0,  0]], dtype=int64)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer(text_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "Check the frequency of each token (you can use `tf.unique_with_counts`). What's the problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UniqueWithCounts(y=<tf.Tensor: shape=(99,), dtype=int64, numpy=\n",
       "array([43,  1, 12, 35, 32, 40, 28, 15, 10,  7, 44, 14, 60,  2, 86, 42, 13,\n",
       "       23,  4,  5, 50,  8, 36, 22,  3, 17, 38, 49,  6,  9, 20, 34, 88, 30,\n",
       "       29, 39, 83, 11, 62, 82, 18, 47, 45, 84, 90, 75, 65, 24, 46, 63, 59,\n",
       "       27, 98, 57, 26, 31, 21, 93, 66, 67, 78, 81, 73, 91, 51, 41, 52, 85,\n",
       "       25, 72, 96, 53, 16, 19, 37, 80, 74, 70, 99, 76, 54, 56, 58, 94, 64,\n",
       "       55, 61, 79, 92, 77, 48, 33, 71, 68, 97, 69, 95, 89, 87],\n",
       "      dtype=int64)>, idx=<tf.Tensor: shape=(22273,), dtype=int32, numpy=array([ 0,  1,  2, ..., 42, 19,  1])>, count=<tf.Tensor: shape=(99,), dtype=int32, numpy=\n",
       "array([   62, 11162,   233,    81,    95,    71,   103,   165,   234,\n",
       "         402,    64,   176,    44,  1341,    34,    69,   174,   116,\n",
       "         641,   614,    54,   378,    75,   126,   661,   161,    72,\n",
       "          53,   523,   274,   133,    77,    31,    95,    96,    61,\n",
       "          31,   237,    41,    34,   159,    57,    66,    32,    28,\n",
       "          37,    43,   112,    53,    41,    50,   105,    30,    52,\n",
       "          99,    97,   133,    33,    38,    39,    41,    35,    38,\n",
       "          24,    58,    64,    53,    28,   110,    38,    26,    53,\n",
       "         158,   123,    76,    37,    32,    33,    26,    37,    53,\n",
       "          43,    49,    29,    38,    48,    42,    37,    26,    34,\n",
       "          53,    87,    40,    40,    31,    40,    34,    28,    33])>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.unique_with_counts(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UniqueWithCounts(y=<tf.Tensor: shape=(99,), dtype=int64, numpy=\n",
       "array([ 2,  1,  7,  3, 12, 19, 33, 36, 21,  8, 10, 17, 41, 18,  5, 73, 26,\n",
       "        4, 22, 68,  9, 91, 55, 66, 29,  6, 23, 67, 25, 44, 97, 56, 11, 64,\n",
       "       15, 42, 86, 30, 34, 16, 94, 27, 83, 92, 14, 38, 74, 70, 13, 20, 50,\n",
       "       61, 39, 46, 24, 82, 71, 28, 90, 51, 76, 52, 60, 43, 32, 85, 49, 47,\n",
       "       89, 84, 75, 63, 62, 37, 81, 54, 69, 77, 87, 35, 58, 31, 98, 48, 99,\n",
       "       93, 59, 96, 40, 45, 53, 65, 78, 57, 79, 72, 88, 95, 80],\n",
       "      dtype=int64)>, idx=<tf.Tensor: shape=(3977,), dtype=int32, numpy=array([ 0,  1,  1, ..., 49,  1,  1])>, count=<tf.Tensor: shape=(99,), dtype=int32, numpy=\n",
       "array([ 275, 1978,   87,  104,   38,   40,   14,   16,   22,   51,   52,\n",
       "         24,   15,   23,  115,    5,   22,  127,   22,    6,   43,   12,\n",
       "         11,    9,   16,   94,   14,    7,   20,    8,    3,   14,   57,\n",
       "          9,   29,    8,    3,   17,   14,   20,    5,   15,    9,    9,\n",
       "         26,   13,   11,   12,   37,   25,   10,   10,   17,   13,   17,\n",
       "          5,    4,   16,    7,    6,    5,    7,    8,   13,   11,    9,\n",
       "          9,    9,   10,    7,    5,   10,    8,   10,    4,    5,    5,\n",
       "          8,    5,    8,    6,   10,    3,   12,    7,    4,    3,    9,\n",
       "         10,    6,    9,    5,    1,    6,    5,    4,    6,    2,    2])>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.unique_with_counts(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feedforward NN\n",
    "### Exercise 8\n",
    "Fit a feedforward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(22273, 5), dtype=int64, numpy=\n",
       "array([[31,  5,  2, 82,  1],\n",
       "       [ 5,  2, 82,  1, 43],\n",
       "       [ 2, 82,  1, 43,  1],\n",
       "       ...,\n",
       "       [ 2,  1,  3,  1,  1],\n",
       "       [ 1,  3,  1,  1, 45],\n",
       "       [ 3,  1,  1, 45,  5]], dtype=int64)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 100), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.one_hot(X_train[0], depth=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ category_encoding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CategoryEncoding</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,032</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,300</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ category_encoding (\u001b[38;5;33mCategoryEncoding\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m100\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │          \u001b[38;5;34m16,032\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │           \u001b[38;5;34m3,300\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,332</span> (75.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,332\u001b[0m (75.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,332</span> (75.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,332\u001b[0m (75.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input = tf.keras.Input(shape=(sequence_length,), dtype=\"int64\") \n",
    "#emd = tf.one_hot(input, depth=vocab_size)\n",
    "emd = layers.CategoryEncoding(num_tokens=vocab_size, output_mode='one_hot')(input)\n",
    "flat = layers.Flatten()(emd) #It has exactly 5 ones, since each token has exactly one 1, 5 tokens -> 5 ones\n",
    "x = layers.Dense(32)(flat) #32[biases] + (32*500)[weights] parameters\n",
    "output = layers.Dense(vocab_size, activation=\"softmax\")(x) #Again 100 [biases] + (100*32) [weights]\n",
    "model = tf.keras.Model(input, output) \n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy being around 50% would be \"quite okay\", considering that a random guess would be $\\frac{1}{100}$ is a better perfomance of around 50 times. However since we have so many unknowns, 50% would probably be achieved by only always choosing unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4996 - loss: 2.3969 - val_accuracy: 0.4969 - val_loss: 2.4446\n",
      "Epoch 2/20\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5051 - loss: 2.3628 - val_accuracy: 0.4956 - val_loss: 2.4373\n",
      "Epoch 3/20\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5065 - loss: 2.3345 - val_accuracy: 0.4966 - val_loss: 2.4296\n",
      "Epoch 4/20\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5091 - loss: 2.3271 - val_accuracy: 0.4969 - val_loss: 2.4244\n",
      "Epoch 5/20\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5051 - loss: 2.3132 - val_accuracy: 0.4964 - val_loss: 2.4229\n",
      "Epoch 6/20\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5026 - loss: 2.3126 - val_accuracy: 0.4969 - val_loss: 2.4213\n",
      "Epoch 7/20\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5115 - loss: 2.2591 - val_accuracy: 0.4966 - val_loss: 2.4148\n",
      "Epoch 8/20\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5057 - loss: 2.2780 - val_accuracy: 0.4971 - val_loss: 2.4115\n",
      "Epoch 9/20\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5034 - loss: 2.2729 - val_accuracy: 0.4964 - val_loss: 2.4144\n",
      "Epoch 10/20\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5111 - loss: 2.2363 - val_accuracy: 0.4969 - val_loss: 2.4140\n",
      "Epoch 11/20\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5083 - loss: 2.2497 - val_accuracy: 0.4953 - val_loss: 2.4096\n",
      "Epoch 12/20\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5098 - loss: 2.2272 - val_accuracy: 0.4964 - val_loss: 2.4118\n",
      "Epoch 13/20\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5050 - loss: 2.2445 - val_accuracy: 0.4951 - val_loss: 2.4137\n",
      "Epoch 14/20\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5060 - loss: 2.2240 - val_accuracy: 0.4933 - val_loss: 2.4133\n",
      "Epoch 15/20\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5096 - loss: 2.2010 - val_accuracy: 0.4961 - val_loss: 2.4165\n",
      "Epoch 16/20\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5092 - loss: 2.2002 - val_accuracy: 0.4951 - val_loss: 2.4161\n",
      "Epoch 17/20\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5059 - loss: 2.2019 - val_accuracy: 0.4956 - val_loss: 2.4192\n",
      "Epoch 18/20\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5076 - loss: 2.1806 - val_accuracy: 0.4943 - val_loss: 2.4200\n",
      "Epoch 19/20\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5125 - loss: 2.1722 - val_accuracy: 0.4898 - val_loss: 2.4221\n",
      "Epoch 20/20\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5113 - loss: 2.1606 - val_accuracy: 0.4923 - val_loss: 2.4238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x177e77e3810>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs = 20, \n",
    "    batch_size=128) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3977, 5])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat.shape == (X_val.shape[0], vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(yhat[100])\n",
    "plt.axvline(x = 1, label = \"Unknown category\", color = 'red', linestyle = 'dashed')\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.argmax(model.predict(X_val), axis = 1)!=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SimpleRNN\n",
    "### Exercise 9 \n",
    "Fit a NN with a `SimpleRNN` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ category_encoding_4                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CategoryEncoding</span>)                   │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,300</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ category_encoding_4                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m100\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mCategoryEncoding\u001b[0m)                   │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_3 (\u001b[38;5;33mSimpleRNN\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m4,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │           \u001b[38;5;34m3,300\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,556</span> (29.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,556\u001b[0m (29.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,556</span> (29.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,556\u001b[0m (29.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input = tf.keras.Input(shape=(sequence_length,), dtype=\"int64\") \n",
    "emd = layers.CategoryEncoding(num_tokens=vocab_size, output_mode='one_hot')(input)\n",
    "x = layers.SimpleRNN(32)(emd) \n",
    "output = layers.Dense(vocab_size, activation=\"softmax\")(x) \n",
    "model = tf.keras.Model(input, output) \n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not interpret metric identifier: AIC",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m \n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\metrics\\__init__.py:206\u001b[0m, in \u001b[0;36mget\u001b[1;34m(identifier)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not interpret metric identifier: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midentifier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Could not interpret metric identifier: AIC"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs = 10, \n",
    "    batch_size=128) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 748us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.argmax(model.predict(X_val), axis = 1)!=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LSTM\n",
    "### Exercise 10\n",
    "Fit a NN with a `LSTM` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 5)]               0         \n",
      "                                                                 \n",
      " tf.one_hot_2 (TFOpLambda)   (None, 5, 100)            0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                17024     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               3300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,324\n",
      "Trainable params: 20,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = tf.keras.Input(shape=(sequence_length,), dtype=\"int64\") \n",
    "emd = tf.one_hot(input, depth=vocab_size)\n",
    "x = layers.LSTM(32)(emd) \n",
    "output = layers.Dense(vocab_size, activation=\"softmax\")(x) \n",
    "model = tf.keras.Model(input, output) \n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "175/175 [==============================] - 2s 5ms/step - loss: 3.1338 - accuracy: 0.4934 - val_loss: 2.6688 - val_accuracy: 0.4974\n",
      "Epoch 2/10\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 2.6701 - accuracy: 0.5011 - val_loss: 2.6611 - val_accuracy: 0.4974\n",
      "Epoch 3/10\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 2.6612 - accuracy: 0.5011 - val_loss: 2.6666 - val_accuracy: 0.4974\n",
      "Epoch 4/10\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 2.6526 - accuracy: 0.5011 - val_loss: 2.6457 - val_accuracy: 0.4974\n",
      "Epoch 5/10\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 2.6446 - accuracy: 0.5011 - val_loss: 2.6535 - val_accuracy: 0.4974\n",
      "Epoch 6/10\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 2.6369 - accuracy: 0.5011 - val_loss: 2.6459 - val_accuracy: 0.4974\n",
      "Epoch 7/10\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 2.6285 - accuracy: 0.5011 - val_loss: 2.6285 - val_accuracy: 0.4974\n",
      "Epoch 8/10\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 2.6187 - accuracy: 0.5011 - val_loss: 2.6180 - val_accuracy: 0.4974\n",
      "Epoch 9/10\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 2.6083 - accuracy: 0.5011 - val_loss: 2.6065 - val_accuracy: 0.4974\n",
      "Epoch 10/10\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 2.5958 - accuracy: 0.5011 - val_loss: 2.5951 - val_accuracy: 0.4974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2162dc983d0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs = 10, \n",
    "    batch_size=128) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 957us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.argmax(model.predict(X_val), axis = 1)!=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Embedding + LSTM\n",
    "### Exercise 11\n",
    "Fit a NN with an `Embedding` and `LSTM` layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 5)]               0         \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     (None, 5, 16)             1600      \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 32)                6272      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 100)               3300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,172\n",
      "Trainable params: 11,172\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = tf.keras.Input(shape=(sequence_length,), dtype=\"int64\") \n",
    "emd = layers.Embedding(input_dim=vocab_size, output_dim=16)(input)\n",
    "x = layers.LSTM(32)(emd) \n",
    "output = layers.Dense(vocab_size, activation=\"softmax\")(x) \n",
    "model = tf.keras.Model(input, output) \n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "349/349 [==============================] - 2s 3ms/step - loss: 2.9095 - accuracy: 0.4995 - val_loss: 2.6744 - val_accuracy: 0.4974\n",
      "Epoch 2/10\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 2.6674 - accuracy: 0.5011 - val_loss: 2.6702 - val_accuracy: 0.4974\n",
      "Epoch 3/10\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 2.6484 - accuracy: 0.5011 - val_loss: 2.6391 - val_accuracy: 0.4974\n",
      "Epoch 4/10\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 2.6317 - accuracy: 0.5011 - val_loss: 2.6472 - val_accuracy: 0.4974\n",
      "Epoch 5/10\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 2.6192 - accuracy: 0.5011 - val_loss: 2.6281 - val_accuracy: 0.4974\n",
      "Epoch 6/10\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 2.6012 - accuracy: 0.5011 - val_loss: 2.5927 - val_accuracy: 0.4974\n",
      "Epoch 7/10\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 2.5761 - accuracy: 0.5011 - val_loss: 2.5668 - val_accuracy: 0.4974\n",
      "Epoch 8/10\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 2.5509 - accuracy: 0.5011 - val_loss: 2.5478 - val_accuracy: 0.4974\n",
      "Epoch 9/10\n",
      "349/349 [==============================] - 1s 3ms/step - loss: 2.5294 - accuracy: 0.5011 - val_loss: 2.5305 - val_accuracy: 0.4974\n",
      "Epoch 10/10\n",
      "349/349 [==============================] - 1s 3ms/step - loss: 2.5127 - accuracy: 0.5012 - val_loss: 2.5162 - val_accuracy: 0.4974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2164d3d1910>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs = 10, \n",
    "    batch_size=64) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.argmax(model.predict(X_val), axis = 1)!=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
